### 总结

这次实验中，学习并实践使用了逻辑回归进行训练与预测，并与前面学习的KNN与贝叶斯方法进行了性能比较。

#### 一、三个常用图像数据集的分类性能比较

| 分类方法\数据集 | 17flowers | Digits | Face images |
| :-------------: | :-------: | :----: | :---------: |
|       KNN       |  20.22%   | 98.89% |   100.0%    |
|   NaiveBayes    |  29.78%   | 82.22% |   100.0%    |
|LogisticRegression|  29.04%  | 97.22% |   100.0%    |

在分类准确率方面，各分类器各有优劣，KNN与逻辑回归分类在Digits中表现优于贝叶斯方法不少；
但同时，贝叶斯方法和逻辑回归又在17flowers数据集中相较KNN占据优势。
从正确率方面，选择LR比其他两个数据集来的更加稳定（虽然不少最高，但也与最高相差无几）。

接下来是时间消耗：

| 分类方法\数据集 | 17flowers | Digits | Face images |
| :-------------: | :-------: | :----: | :---------: |
|       KNN       |  0.031s \| 0.812s  | 0.001s \| 0.015s |  0.001s \| 0.033s  |
|   NaiveBayes    |  0.283s \| 1.45s  | 0.001s \| 0.001s |   0.059s \| 0.101s   |
|LogisticRegression|  14.9s \| 0.035s  | 0.096s \| 0.001s |   1.97s \| 0.004s   |

训练时间上一般为：KNN > NaiveBayes > LogisticRegression，
但预测时间则相反：LogisticRegression > NaiveBayes > KNN。
KNN前面已经介绍很多了，其特点快训练、慢预测的特点就不再展开了。
LR的训练需要经过优化算法不断迭代，需要进行较多的计算，但是但回归函数一旦确定，只需带入计算即可获得结果，最大时间复杂度仅为O(n)。
属于慢训练、快预测，与神经网络的思想有类似之处。

#### 二、cifar10的三个批次性能比较

各批次准确率如下：

| 分类方法\数据集 | batch_1   | batch_2| batch_3     |
| :-------------: | :-------: | :----: | :---------: |
|       KNN       |  28.97%   | 28.88% |   30.28%    |
|   NaiveBayes    |  29.29%   | 29.85% |   29.58%    |
|LogisticRegression|  37.17%  | 37.44% |   36.73%    |

时间方面与上面结论一致，就不再展示了。
逻辑回归的训练时长是KNN的10000+倍，预测消耗为KNN的1/55，各有各的特点。（贝叶斯刚好夹在中间）
